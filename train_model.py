import pandas as pd
import re
import os
import sys
from pyvi import ViTokenizer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import joblib
import numpy as np

# =============================
# âš™ï¸ Cáº¤U HÃŒNH
# =============================
EXCEL_FILE_PATH = './du_lieu_tin_tuc.xlsx'   # Dá»¯ liá»‡u 1000 dÃ²ng
TEXT_COLUMN_NAME = 'content'
LABEL_COLUMN_NAME = 'label'
VIETNAMESE_STOPWORDS_PATH = './vietnamese-stopwords.txt'
MODEL_SAVE_PATH = './fake_news_rf_model.pkl'
# =============================

# -----------------------------
# ğŸ§© HÃ€M Xá»¬ LÃ Dá»® LIá»†U
# -----------------------------
def load_stopwords(file_path):
    """Äá»c danh sÃ¡ch stopword tiáº¿ng Viá»‡t."""
    if not os.path.exists(file_path):
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file stopword táº¡i '{file_path}'. Bá» qua.")
        return []
    with open(file_path, 'r', encoding='utf-8') as f:
        stopwords = [line.strip() for line in f if line.strip()]
    print(f"âœ… Táº£i {len(stopwords)} stopword thÃ nh cÃ´ng.")
    return stopwords

def preprocess_text(text):
    """Tiá»n xá»­ lÃ½ vÄƒn báº£n cÆ¡ báº£n."""
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r"http\S+", "", text)     # XÃ³a URL
    text = re.sub(r"\d+", "", text)         # XÃ³a sá»‘
    text = re.sub(r"[^\w\s]", " ", text)    # XÃ³a kÃ½ tá»± Ä‘áº·c biá»‡t
    text = re.sub(r"\s+", " ", text).strip()
    return text

def vi_tokenizer(text):
    """TÃ¡ch tá»« tiáº¿ng Viá»‡t."""
    tokenized = ViTokenizer.tokenize(text)
    return tokenized.split()

def load_data(file_path, text_col, label_col):
    """Äá»c file dá»¯ liá»‡u vÃ  xá»­ lÃ½."""
    try:
        df = pd.read_excel(file_path)
        if text_col not in df.columns or label_col not in df.columns:
            print(f"âŒ Thiáº¿u cá»™t '{text_col}' hoáº·c '{label_col}'.")
            sys.exit(1)

        df[text_col] = df[text_col].apply(preprocess_text)
        df[label_col] = pd.to_numeric(df[label_col], errors='coerce')
        df = df.dropna(subset=[text_col, label_col])
        df = df[df[text_col].str.len() > 0]
        df[label_col] = df[label_col].astype(int)

        print(f"âœ… Dá»¯ liá»‡u há»£p lá»‡: {len(df)} máº«u")
        print("ğŸ“Š Thá»‘ng kÃª nhÃ£n:")
        print(df[label_col].value_counts())
        return df[text_col], df[label_col]
    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c dá»¯ liá»‡u: {e}")
        sys.exit(1)

# -----------------------------
# ğŸš€ HÃ€M CHÃNH
# -----------------------------
def main():
    print("ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest phÃ¢n loáº¡i tin tháº­t/giáº£...")
    stopwords = load_stopwords(VIETNAMESE_STOPWORDS_PATH)

    if not os.path.exists(EXCEL_FILE_PATH):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file '{EXCEL_FILE_PATH}'")
        return

    X, y = load_data(EXCEL_FILE_PATH, TEXT_COLUMN_NAME, LABEL_COLUMN_NAME)

    # TF-IDF
    print("ğŸ”¤ TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng TF-IDF...")
    tfidf = TfidfVectorizer(
        tokenizer=vi_tokenizer,
        stop_words=stopwords if stopwords else None,
        max_df=0.85,
        min_df=1,
        max_features=15000
    )

    X_tfidf = tfidf.fit_transform(X)
    print(f"âœ… Sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng: {len(tfidf.get_feature_names_out())}")

    # MÃ´ hÃ¬nh Random Forest
    rf_model = RandomForestClassifier(
        n_estimators=300,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=3,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )

    # Cross Validation (5-fold)
    print("ğŸ§ª Äang Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh (5-fold cross validation)...")
    scores = cross_val_score(rf_model, X_tfidf, y, cv=5, scoring='accuracy')
    print(f"ğŸ“ˆ Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh: {scores.mean()*100:.2f}%")

    # Chia dá»¯ liá»‡u train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X_tfidf, y, test_size=0.2, random_state=42, stratify=y
    )

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    print("ğŸŒ² Huáº¥n luyá»‡n Random Forest...")
    rf_model.fit(X_train, y_train)
    print("âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")

    # ÄÃ¡nh giÃ¡
    y_pred = rf_model.predict(X_test)
    print("\nğŸ“Š Ma tráº­n nháº§m láº«n:")
    print(confusion_matrix(y_test, y_pred))
    print("\nğŸ“‹ BÃ¡o cÃ¡o chi tiáº¿t:")
    print(classification_report(y_test, y_pred, target_names=['Tháº­t (0)', 'Giáº£ (1)']))

    print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c kiá»ƒm thá»­: {accuracy_score(y_test, y_pred)*100:.2f}%")

    # LÆ°u mÃ´ hÃ¬nh
    joblib.dump((rf_model, tfidf), MODEL_SAVE_PATH)
    print(f"ğŸ’¾ ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ o: {MODEL_SAVE_PATH}")

    # Dá»± Ä‘oÃ¡n thá»­
    print("\n--- ğŸ”® Dá»° ÄOÃN THá»¬ ---")
    test_articles = [
        "Bá»™ Y táº¿ khuyáº¿n cÃ¡o ngÆ°á»i dÃ¢n tiÃªm phÃ²ng cÃºm mÃ¹a Ä‘á»ƒ phÃ²ng dá»‹ch.",
        "ToÃ n bá»™ ngÆ°á»i dÃ¢n sáº½ Ä‘Æ°á»£c nháº­n 10 triá»‡u Ä‘á»“ng tá»« ChÃ­nh phá»§ trong thÃ¡ng tá»›i.",
        "Uá»‘ng nÆ°á»›c lÃ¡ Ä‘u Ä‘á»§ chá»¯a Ä‘Æ°á»£c ung thÆ° giai Ä‘oáº¡n cuá»‘i.",
        "GiÃ¡ xÄƒng dáº§u trong nÆ°á»›c tÄƒng nháº¹ theo thá»‹ trÆ°á»ng tháº¿ giá»›i.",
        "Cáº£nh bÃ¡o mÃ£ Ä‘á»™c má»›i lÃ¢y qua Facebook chá»‰ báº±ng cÃ¡ch nháº¥n Like."
    ]
    for text in test_articles:
        clean_text = preprocess_text(text)
        vec = tfidf.transform([clean_text])
        pred = rf_model.predict(vec)[0]
        prob = rf_model.predict_proba(vec)[0][pred]
        print(f"\nğŸ“° {text}")
        print(f"â†’ Dá»± Ä‘oÃ¡n: {'Giáº£ (1)' if pred == 1 else 'Tháº­t (0)'} (Äá»™ tin cáº­y: {prob*100:.2f}%)")

# -----------------------------
if __name__ == "__main__":
    main()
